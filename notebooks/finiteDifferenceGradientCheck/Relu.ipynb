{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96cc38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_operator import Relu, Relu_backward\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a5b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c80ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73055323",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "T = 4\n",
    "C = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d098d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 2 * (rng.random((B, T, C), np.float64) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99891f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dY = 2 * (rng.random((B, T, C), np.float64) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54131aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.04277148,  0.20768369, -0.05811641, -0.59350411,\n",
       "          0.05751805, -0.61792744],\n",
       "        [-0.4369088 ,  0.5073631 ,  0.10334355,  0.72744415,\n",
       "          0.61074444, -0.50325467],\n",
       "        [-0.62028518,  0.96799116,  0.33999433, -0.43923434,\n",
       "         -0.59217353,  0.25012937],\n",
       "        [ 0.30520863,  0.79761506,  0.94952756, -0.69213526,\n",
       "          0.39817855, -0.10551711]],\n",
       "\n",
       "       [[-0.96497358, -0.41795019, -0.23752678, -0.35794418,\n",
       "          0.88508934,  0.40533395],\n",
       "        [-0.72709936, -0.31358185,  0.62398921, -0.703012  ,\n",
       "         -0.88134862, -0.37116673],\n",
       "        [-0.15968709,  0.61603542, -0.98098483, -0.09183242,\n",
       "          0.11737397, -0.99422273],\n",
       "        [-0.40448486, -0.89240178,  0.13533751,  0.8811163 ,\n",
       "          0.44854743,  0.71275618]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a6cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, relu_cache = Relu(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63f26682",
   "metadata": {},
   "outputs": [],
   "source": [
    "dX_num = np.zeros_like(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cddd4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_check_Activation(activate, activate_backword, eps=1e-6):\n",
    "    rng = np.random.default_rng(1000)\n",
    "\n",
    "    B, T, C = 2, 4, 6\n",
    "    X = 2 * rng.random((B, T, C), dtype=np.float64) - 1\n",
    "    dY = 2 * rng.random((B, T, C), dtype=np.float64) - 1\n",
    "\n",
    "    # forward\n",
    "    Y, cache = activate(X)\n",
    "\n",
    "    # analytical gradient\n",
    "    dX = activate_backword(dY, cache)\n",
    "\n",
    "    # numerical gradient\n",
    "    dX_num = np.zeros_like(X)\n",
    "    \n",
    "    iteration = np.nditer(X, flags=[\"multi_index\"], op_flags=['readwrite'])\n",
    "    while not iteration.finished:\n",
    "        idx = iteration.multi_index\n",
    "        # print(idx)\n",
    "        old = X[idx]\n",
    "\n",
    "        X[idx] = old + epsilon\n",
    "        Yp, _ = activate(X)\n",
    "        Lp = np.sum(Yp * dY)\n",
    "\n",
    "        X[idx] = old - epsilon\n",
    "        Ym, _ = activate(X)\n",
    "        Lm = np.sum(Ym * dY)\n",
    "\n",
    "        X[idx] = old\n",
    "        dX_num[idx] = (Lp - Lm) / (2 * eps)\n",
    "\n",
    "        iteration.iternext()\n",
    "\n",
    "    max_abs = np.max(np.abs(dX - dX_num))\n",
    "    rel = max_abs / (np.max(np.abs(dX) + np.abs(dX_num)) + 1e-22)\n",
    "\n",
    "    print(\"max_abs_diff:\", max_abs)\n",
    "    print(\"relative_diff:\", rel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a015b8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_abs_diff: 1.9616686053325338e-10\n",
      "relative_diff: 1.0041134203920265e-10\n"
     ]
    }
   ],
   "source": [
    "grad_check_Activation(Relu, Relu_backward, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e26cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-scratch)",
   "language": "python",
   "name": "llm-scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
