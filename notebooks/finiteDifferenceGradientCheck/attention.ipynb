{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd80f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformer import Attention, Attention_cache, Attention_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = 2, 4, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba54380",
   "metadata": {},
   "source": [
    "``` python\n",
    "@dataclass\n",
    "class Attention_init:\n",
    "    gamma: npt.NDArray[np.float64] # (1, 1, C) or (C, )\n",
    "    beta: npt.NDArray[np.float64]  # (1, 1, C) or (C, )\n",
    "\n",
    "    attentionHead: int             # H\n",
    "\n",
    "    Wk: npt.NDArray[np.float64]    # (C, C) when C is hidden param or d_model\n",
    "    Wq: npt.NDArray[np.float64]    # (C, C)\n",
    "    Wv: npt.NDArray[np.float64]    # (C, C)\n",
    "\n",
    "    merge_heads_bias: npt.NDArray[np.float64] # (1, 1, C) recommend\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c1108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attentionInit = Attention_init(\n",
    "    gamma=  rng.random((1, 1, C), dtype = np.float64),\n",
    "    beta= rng.random((1, 1, C), dtype=np.float64),\n",
    "    attentionHead= 2,\n",
    "    Wk=rng.random((1, C, C), np.float64),\n",
    "    Wq = rng.random((1, C, C), np.float64),\n",
    "    Wv = rng.random((1, C, C), np.float64),\n",
    "    merge_heads_bias=rng.random((1, 1, C), np.float64),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b32ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336cd1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = Attention(attentionInit, \"attentiondemo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36983b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_check_transformer(forward, backward, eps=1e-6):\n",
    "    rng = np.random.default_rng(1000)\n",
    "\n",
    "    B, T, C = 2, 4, 6\n",
    "\n",
    "    X = -rng.random((B, T, C), dtype=np.float64)\n",
    "    G = -rng.random((B, T, C), dtype=np.float64) # upstream gradient\n",
    "\n",
    "    # forward\n",
    "    Y = forward(X)\n",
    "\n",
    "    # analytical gradient\n",
    "    dX = backward(G)\n",
    "\n",
    "    # numerical gradient\n",
    "    dX_num = np.zeros_like(X)\n",
    "    it = np.nditer(X, flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        old = X[idx]\n",
    "\n",
    "        X[idx] = old + eps\n",
    "        Yp = forward(X)\n",
    "        Lp = np.sum(Yp * G)\n",
    "\n",
    "        X[idx] = old - eps\n",
    "        Ym = forward(X)\n",
    "        Lm = np.sum(Ym * G)\n",
    "\n",
    "        X[idx] = old\n",
    "        dX_num[idx] = (Lp - Lm) / (2 * eps)\n",
    "\n",
    "        it.iternext()\n",
    "\n",
    "    # compare\n",
    "\n",
    "    max_abs = np.max(np.abs(dX - dX_num))\n",
    "    rel = max_abs / (np.max(np.abs(dX) + np.abs(dX_num)) + 1e-22)\n",
    "\n",
    "\n",
    "    print(\"max_abs_diff:\", max_abs)\n",
    "    print(\"relative_diff:\", rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aec20d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "attentions shape:  (2, 2, 4, 4)\n",
      "max_abs_diff: 6.648335326708832e-09\n",
      "relative_diff: 3.9791326724049783e-10\n"
     ]
    }
   ],
   "source": [
    "grad_check_transformer(forward=attention.forward_train, backward=attention.backward, eps=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923a512",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4035325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rng.random((B, T, C), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd63e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attentions shape:  (2, 2, 4, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[2.77032307, 2.2105829 , 2.52775936, 2.69479426, 1.68536338,\n",
       "         3.21748881],\n",
       "        [2.74529813, 2.16836401, 2.49016752, 2.68981458, 1.68009357,\n",
       "         3.22711317],\n",
       "        [2.77963157, 2.2348538 , 2.54364789, 2.70219641, 1.69810062,\n",
       "         3.25003861],\n",
       "        [2.65564606, 2.00655827, 2.35375729, 2.6648596 , 1.65775292,\n",
       "         3.21420054]],\n",
       "\n",
       "       [[2.22650873, 1.87800909, 2.13418968, 2.74701142, 1.74512249,\n",
       "         2.7880826 ],\n",
       "        [2.14025484, 1.71911558, 2.03538611, 2.64239026, 1.64277495,\n",
       "         2.73893187],\n",
       "        [2.2041275 , 1.85006603, 2.11041965, 2.74007921, 1.73570707,\n",
       "         2.78968666],\n",
       "        [2.16643853, 1.79641102, 2.06787027, 2.66498002, 1.66682112,\n",
       "         2.7459665 ]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.forward_train(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a840f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 4, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.Q_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427c521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 4, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.K_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb80fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[3.83496518, 3.91845587, 5.37339579, 2.68240767],\n",
       "         [3.15911386, 3.19127673, 4.57904803, 2.38957341],\n",
       "         [3.9229944 , 3.98181699, 5.67189336, 2.95385506],\n",
       "         [1.66152568, 1.62701761, 2.47209586, 1.32392322]],\n",
       "\n",
       "        [[5.3130294 , 4.5760051 , 5.00512947, 1.41665579],\n",
       "         [4.86950489, 4.25931395, 4.71681246, 1.34907468],\n",
       "         [6.81921798, 5.99585957, 6.66014132, 1.97908475],\n",
       "         [3.57308366, 3.18681124, 3.57748393, 1.08859133]]],\n",
       "\n",
       "\n",
       "       [[[3.93651729, 2.97079215, 4.1935504 , 2.77173733],\n",
       "         [1.75224639, 1.43867577, 1.91423718, 1.27401304],\n",
       "         [3.4592222 , 2.69459272, 3.70621879, 2.39239388],\n",
       "         [2.47423822, 1.9542011 , 2.6357916 , 1.57781742]],\n",
       "\n",
       "        [[5.02852816, 1.76379282, 4.32497193, 2.32321157],\n",
       "         [3.34775732, 1.30827139, 3.05638825, 1.70954982],\n",
       "         [5.07391599, 1.81862409, 4.44611525, 2.47981239],\n",
       "         [3.50578726, 1.29242308, 3.08662797, 1.66277238]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a692f0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 4, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f6d87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.merge_heads(attention.output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661de585",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = -rng.random((B, T, C), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a5368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-scratch)",
   "language": "python",
   "name": "llm-scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
